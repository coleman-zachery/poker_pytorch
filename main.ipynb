{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228e169",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ddf8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANKS = \"_?W23456789XJQKA\"\n",
    "SUITS = \"_?W♣♦♥♠\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e7c433",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def card_str_to_tuple(card_str):\n",
    "    rank_char, suit_char = card_str\n",
    "    rank = RANKS.index(rank_char)\n",
    "    suit = SUITS.index(suit_char)\n",
    "    return (rank, suit)\n",
    "\n",
    "def classify_poker_hand(card_tuples):\n",
    "    ranks = [rank for rank, _ in card_tuples if rank > 2]\n",
    "    rank_counts = {rank: ranks.count(rank) for rank in set(ranks)}\n",
    "    wild_ranks = [rank for rank, _ in card_tuples if rank == 2]\n",
    "    is_flush = len(set(suit for _, suit in card_tuples if suit > 1)) == 1\n",
    "    sorted_ranks = sorted(ranks)\n",
    "    # check for straight (including low-Ace straight)\n",
    "    is_straight = False\n",
    "    if len(sorted_ranks) >= 5:\n",
    "        if sorted_ranks == list(range(sorted_ranks[0], sorted_ranks[0] + 5)):\n",
    "            is_straight = True\n",
    "        elif sorted_ranks[-4:] == [10, 11, 12, 13] and sorted_ranks[0] == 14:\n",
    "            is_straight = True\n",
    "\n",
    "    if is_straight and is_flush and sorted_ranks[-1] == 14:\n",
    "        return \"royal flush\"\n",
    "    elif is_straight and is_flush:\n",
    "        return \"straight flush\"\n",
    "    elif 4 in rank_counts.values():\n",
    "        return \"four of a kind\"\n",
    "    elif 3 in rank_counts.values() and 2 in rank_counts.values():\n",
    "        return \"full house\"\n",
    "    elif is_flush:\n",
    "        return \"flush\"\n",
    "    elif is_straight:\n",
    "        return \"straight\"\n",
    "    elif 3 in rank_counts.values():\n",
    "        return \"three of a kind\"\n",
    "    elif list(rank_counts.values()).count(2) == 2:\n",
    "        return \"two pair\"\n",
    "    elif 2 in rank_counts.values():\n",
    "        return \"one pair\"\n",
    "    elif len(ranks) > 0:\n",
    "        return \"high card\"\n",
    "    else:\n",
    "        return \"nothing\"\n",
    "\n",
    "def poker_hand_label_to_index(label):\n",
    "    label_map = {\n",
    "        \"nothing\": 0,\n",
    "        \"high card\": 1,\n",
    "        \"one pair\": 2,\n",
    "        \"two pair\": 3,\n",
    "        \"three of a kind\": 4,\n",
    "        \"straight\": 5,\n",
    "        \"flush\": 6,\n",
    "        \"full house\": 7,\n",
    "        \"four of a kind\": 8,\n",
    "        \"straight flush\": 9,\n",
    "        \"royal flush\": 10,\n",
    "    }\n",
    "    return label_map[label]\n",
    "\n",
    "def reverse_poker_hand_index(index):\n",
    "    index_map = {\n",
    "        0: \"nothing\",\n",
    "        1: \"high card\",\n",
    "        2: \"one pair\",\n",
    "        3: \"two pair\",\n",
    "        4: \"three of a kind\",\n",
    "        5: \"straight\",\n",
    "        6: \"flush\",\n",
    "        7: \"full house\",\n",
    "        8: \"four of a kind\",\n",
    "        9: \"straight flush\",\n",
    "        10: \"royal flush\",\n",
    "    }\n",
    "    return index_map[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04579aea",
   "metadata": {},
   "source": [
    "#### Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardEncoder(nn.Module):\n",
    "    def __init__(self, ranks=len(RANKS), suits=len(SUITS), rank_dim=8, suit_dim=4, output_dim=16):\n",
    "        super().__init__()\n",
    "        self.rank_emb = nn.Embedding(ranks, rank_dim)\n",
    "        self.suit_emb = nn.Embedding(suits, suit_dim)\n",
    "        self.fc = nn.Linear(suit_dim + rank_dim, output_dim)\n",
    "\n",
    "    def forward(self, card_tensor):\n",
    "        rank_tensor = card_tensor[:, 0]\n",
    "        suit_tensor = card_tensor[:, 1]\n",
    "        rank_emb = self.rank_emb(rank_tensor)\n",
    "        suit_emb = self.suit_emb(suit_tensor)\n",
    "        combined = torch.cat((rank_emb, suit_emb), dim=-1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n",
    "\n",
    "class PokerHandClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=32, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim * 5, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, hand_tensor):\n",
    "        batch_size = hand_tensor.size(0)\n",
    "        hand_flat = hand_tensor.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(hand_flat))\n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "\n",
    "################################################################\n",
    "################################################################\n",
    "\n",
    "class PokerHandClassifier_WithAttention(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=32, num_classes=11, num_heads=4):\n",
    "        super().__init__()\n",
    "        # self-attention layer lets cards \"interact\"\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=input_dim, num_heads=num_heads, batch_first=True)\n",
    "        \n",
    "        # optional feedforward layer after attention\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, hand_tensor):\n",
    "        # hand_tensor: (batch, num_cards, input_dim)\n",
    "        attn_output, _ = self.attn(hand_tensor, hand_tensor, hand_tensor)\n",
    "        \n",
    "        # permutation-invariant pooling (mean or sum)\n",
    "        pooled = attn_output.mean(dim=1)  # (batch, input_dim)\n",
    "        \n",
    "        x = F.relu(self.fc1(pooled))\n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "\n",
    "################################################################\n",
    "################################################################\n",
    "\n",
    "class PokerHandClassifier_SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=32, num_classes=11, num_heads=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.MultiheadAttention(embed_dim=input_dim, num_heads=num_heads, batch_first=True)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, hand_tensor):\n",
    "        x = hand_tensor\n",
    "        for attn in self.layers:\n",
    "            attn_out, _ = attn(x, x, x)\n",
    "            x = x + attn_out  # residual connection\n",
    "        pooled = x.mean(dim=1)\n",
    "        x = F.relu(self.fc1(pooled))\n",
    "        return self.fc2(x)\n",
    "\n",
    "################################################################\n",
    "################################################################\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, num_cards, input_dim)\n",
    "        attn_scores = self.attn(x)                 # (batch, num_cards, 1)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        pooled = torch.sum(attn_weights * x, dim=1)  # weighted sum (batch, input_dim)\n",
    "        return pooled\n",
    "\n",
    "class PokerHandClassifier_AttentionPooling(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=32, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.pool = AttentionPooling(input_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, hand_tensor):\n",
    "        pooled = self.pool(hand_tensor)\n",
    "        x = F.relu(self.fc1(pooled))\n",
    "        return self.fc2(x)\n",
    "\n",
    "################################################################\n",
    "################################################################\n",
    "\n",
    "class SAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=dim_out, num_heads=num_heads, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim_out, dim_out * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_out * 2, dim_out),\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(dim_out)\n",
    "        self.ln2 = nn.LayerNorm(dim_out)\n",
    "        self.proj = nn.Linear(dim_in, dim_out) if dim_in != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project to match MHA input dimension if necessary\n",
    "        x_proj = self.proj(x)\n",
    "        attn_out, _ = self.mha(x_proj, x_proj, x_proj)\n",
    "        x = self.ln1(x_proj + attn_out)\n",
    "        ff_out = self.fc(x)\n",
    "        return self.ln2(x + ff_out)\n",
    "\n",
    "class PMA(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, num_seeds=1):\n",
    "        super().__init__()\n",
    "        self.seed_vectors = nn.Parameter(torch.randn(num_seeds, dim))\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        seed = self.seed_vectors.unsqueeze(0).repeat(batch_size, 1, 1)  # (B, num_seeds, dim)\n",
    "        out, _ = self.mha(seed, x, x)\n",
    "        return out  # (B, num_seeds, dim)\n",
    "\n",
    "class PokerHandClassifier_SetTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=16, dim_hidden=32, num_heads=4, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.sab1 = SAB(input_dim, dim_hidden, num_heads)\n",
    "        self.sab2 = SAB(dim_hidden, dim_hidden, num_heads)\n",
    "        self.pma = PMA(dim_hidden, num_heads, num_seeds=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim_hidden, dim_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_hidden, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, hand_tensor):\n",
    "        # hand_tensor: (batch, num_cards, input_dim)\n",
    "        x = self.sab1(hand_tensor)\n",
    "        x = self.sab2(x)\n",
    "        x = self.pma(x).squeeze(1)  # (batch, dim_hidden)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- convert card strings to tensor ----\n",
    "def card_strings_to_tensor(card_strings):\n",
    "    card_tuples = [card_str_to_tuple(cs) for cs in card_strings]\n",
    "    card_tensor = torch.tensor(card_tuples, dtype=torch.long)\n",
    "    return card_tensor\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ---- training set ----\n",
    "    card_strings = [\n",
    "        [\"A♥\", \"K♦\", \"Q♣\", \"J♠\", \"__\"], # high card\n",
    "        [\"A♥\", \"K♥\", \"Q♥\", \"J♥\", \"X♥\"], # royal flush\n",
    "        [\"9♠\", \"8♠\", \"7♠\", \"6♠\", \"5♠\"], # straight flush\n",
    "        [\"3♦\", \"3♣\", \"3♥\", \"3♠\", \"9♥\"], # four of a kind\n",
    "        [\"4♥\", \"4♠\", \"4♣\", \"9♦\", \"9♥\"], # full house\n",
    "        [\"2♣\", \"5♣\", \"9♣\", \"J♣\", \"K♣\"], # flush\n",
    "        [\"6♥\", \"5♠\", \"4♦\", \"3♣\", \"2♥\"], # straight\n",
    "        [\"7♠\", \"7♥\", \"7♣\", \"2♦\", \"5♥\"], # three of a kind\n",
    "        [\"8♦\", \"8♣\", \"4♥\", \"4♠\", \"K♥\"], # two pair\n",
    "        [\"J♣\", \"J♠\", \"3♥\", \"6♦\", \"9♣\"], # one pair\n",
    "        [\"5♥\", \"X♠\", \"7♣\", \"4♦\", \"2♥\"], # high card\n",
    "        [\"5♥\", \"5♠\", \"__\", \"__\", \"__\"], # one pair with 3 empty cards\n",
    "        [\"9♣\", \"9♦\", \"4♥\", \"4♠\", \"??\"], # two pair and 1 ?? card\n",
    "        [\"__\", \"__\", \"__\", \"__\", \"__\"], # empty hand\n",
    "    ]\n",
    "\n",
    "    card_tensors = []\n",
    "    labels = []\n",
    "    for hand in card_strings:\n",
    "        card_tensor = card_strings_to_tensor(hand)\n",
    "        card_tensors.append(card_tensor)\n",
    "        card_tuples = [card_str_to_tuple(cs) for cs in hand]\n",
    "        label = classify_poker_hand(card_tuples)\n",
    "        labels.append(poker_hand_label_to_index(label))\n",
    "    card_tensors = torch.stack(card_tensors)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    print(\"Card Tensors:\\n\", card_tensors)\n",
    "    print(\"Labels:\\n\", labels)\n",
    "    encoder = CardEncoder()\n",
    "    # ---- choose classifier ----\n",
    "    classifier = PokerHandClassifier()\n",
    "    # ---- choose classifier ----\n",
    "    encoded_cards = encoder(card_tensors.view(-1, 2))\n",
    "    encoded_hands = encoded_cards.view(card_tensors.size(0), 5, -1)\n",
    "    outputs = classifier(encoded_hands)\n",
    "    print(\"Classifier Outputs:\\n\", outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- train loop ----\n",
    "def train_loop(model, data_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch_cards, batch_labels in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            encoded_cards = encoder(batch_cards.view(-1, 2))\n",
    "            encoded_hands = encoded_cards.view(batch_cards.size(0), 5, -1)\n",
    "            outputs = model(encoded_hands)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Example of setting up a data loader and training\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "dataset = TensorDataset(card_tensors, labels)\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "train_loop(classifier, data_loader, criterion, optimizer, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34407b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- function that outputs the softmax probability for each class >= 1.00%, formatted to .00% and sorted largest to smallest % ----\n",
    "def get_class_probabilities(model, hand_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_cards = encoder(hand_tensor.view(-1, 2))\n",
    "        encoded_hand = encoded_cards.view(1, 5, -1)\n",
    "        outputs = model(encoded_hand)\n",
    "        probabilities = F.softmax(outputs, dim=1).squeeze(0)\n",
    "        significant_probs = {reverse_poker_hand_index(i): prob.item() for i, prob in enumerate(probabilities)}\n",
    "        sorted_probs = dict(sorted(significant_probs.items(), key=lambda item: item[1], reverse=True))\n",
    "        formatted_probs = {k: f\"{v*100:.2f}%\" for k, v in sorted_probs.items()}\n",
    "        return formatted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e84f9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hand: ['A♥', 'K♦', 'Q♣', 'J♠', '__']\n",
      "correct label confidence: high card -- 92.57%\n",
      "\n",
      "hand: ['A♥', 'K♥', 'Q♥', 'J♥', 'X♥']\n",
      "correct label confidence: royal flush -- 94.76%\n",
      "\n",
      "hand: ['9♠', '8♠', '7♠', '6♠', '5♠']\n",
      "correct label confidence: straight flush -- 93.84%\n",
      "\n",
      "hand: ['3♦', '3♣', '3♥', '3♠', '9♥']\n",
      "correct label confidence: four of a kind -- 96.75%\n",
      "\n",
      "hand: ['4♥', '4♠', '4♣', '9♦', '9♥']\n",
      "correct label confidence: full house -- 97.14%\n",
      "\n",
      "hand: ['2♣', '5♣', '9♣', 'J♣', 'K♣']\n",
      "correct label confidence: flush -- 96.68%\n",
      "\n",
      "hand: ['6♥', '5♠', '4♦', '3♣', '2♥']\n",
      "correct label confidence: straight -- 96.17%\n",
      "\n",
      "hand: ['7♠', '7♥', '7♣', '2♦', '5♥']\n",
      "correct label confidence: three of a kind -- 96.17%\n",
      "\n",
      "hand: ['8♦', '8♣', '4♥', '4♠', 'K♥']\n",
      "correct label confidence: two pair -- 98.25%\n",
      "\n",
      "hand: ['J♣', 'J♠', '3♥', '6♦', '9♣']\n",
      "correct label confidence: one pair -- 97.71%\n",
      "\n",
      "hand: ['5♥', 'X♠', '7♣', '4♦', '2♥']\n",
      "correct label confidence: high card -- 96.10%\n",
      "\n",
      "hand: ['5♥', '5♠', '__', '__', '__']\n",
      "correct label confidence: one pair -- 95.78%\n",
      "\n",
      "hand: ['9♣', '9♦', '4♥', '4♠', '??']\n",
      "correct label confidence: two pair -- 95.84%\n",
      "\n",
      "hand: ['__', '__', '__', '__', '__']\n",
      "correct label confidence: nothing -- 95.07%\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-782777335.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mhand_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcard_strings_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mhand_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"royal flush\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mencoded_cards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhand_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mencoded_hand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_cards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_hand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1621098508.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, card_tensor)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mrank_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcard_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msuit_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcard_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mrank_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0msuit_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuit_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuit_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuit_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2544\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# ---- print tensor hands, expected output, and classifier outputs ----\n",
    "for i in range(card_tensors.size(0)):\n",
    "    hand_tensor = card_tensors[i].unsqueeze(0)\n",
    "    expected_label = labels[i].item()\n",
    "    hand_type = reverse_poker_hand_index(expected_label)\n",
    "    encoded_cards = encoder(hand_tensor.view(-1, 2))\n",
    "    encoded_hand = encoded_cards.view(1, 5, -1)\n",
    "    outputs = classifier(encoded_hand)\n",
    "    probabilities = get_class_probabilities(classifier, hand_tensor)\n",
    "    #predicted_label = torch.argmax(outputs, dim=1).item()\n",
    "    hand = card_strings[i]\n",
    "    print(f\"\\nhand: {hand}\")\n",
    "    print(f\"correct label confidence: {hand_type} -- {probabilities[hand_type]}\")\n",
    "\n",
    "# ---- test to see if the model can correctly predict each royal flush hand ----\n",
    "royal_flush_hands = [\n",
    "    [\"A♣\", \"K♣\", \"Q♣\", \"J♣\", \"X♣\"],\n",
    "    [\"A♦\", \"K♦\", \"Q♦\", \"J♦\", \"X♦\"],\n",
    "    [\"A♥\", \"K♥\", \"Q♥\", \"J♥\", \"X♥\"],\n",
    "    [\"A♠\", \"K♠\", \"Q♠\", \"J♠\", \"X♠\"],\n",
    "]\n",
    "\n",
    "for hand in royal_flush_hands:\n",
    "    hand_tensor = card_strings_to_tensor(hand).unsqueeze(0)\n",
    "    hand_type = \"royal flush\"\n",
    "    encoded_cards = encoder(hand_tensor.view(-1, 2))\n",
    "    encoded_hand = encoded_cards.view(1, 5, -1)\n",
    "    outputs = classifier(encoded_hand)\n",
    "    probabilities = get_class_probabilities(classifier, hand_tensor)\n",
    "    print(f\"\\nhand: {hand}\")\n",
    "    print(f\"correct label confidence: {hand_type} -- {probabilities[hand_type]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceb96bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hand: ['__', 'A♣', 'K♦', 'Q♥', 'J?']\n",
      "class probabilities: {'nothing': '59.13%', 'high card': '15.94%', 'four of a kind': '13.88%', 'royal flush': '3.91%', 'one pair': '3.15%', 'straight': '1.38%', 'three of a kind': '1.22%', 'full house': '0.84%', 'flush': '0.30%', 'straight flush': '0.17%', 'two pair': '0.10%'}\n"
     ]
    }
   ],
   "source": [
    "royal_flush_hands = [\n",
    "    [\"__\", \"A♣\", \"K♦\", \"Q♥\", \"J?\"],\n",
    "]\n",
    "\n",
    "for hand in royal_flush_hands:\n",
    "    hand_tensor = card_strings_to_tensor(hand).unsqueeze(0)\n",
    "    encoded_cards = encoder(hand_tensor.view(-1, 2))\n",
    "    encoded_hand = encoded_cards.view(1, 5, -1)\n",
    "    outputs = classifier(encoded_hand)\n",
    "    probabilities = get_class_probabilities(classifier, hand_tensor)\n",
    "    print(f\"\\nhand: {hand}\")\n",
    "    print(f\"class probabilities: {probabilities}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
